"""
íŒŒì¼: fine_tuning.py
ì„¤ëª…: Uni-Sign í•™ìŠµì‹œ Wandb ë¡œê¹… ì¶”ê°€

ì‘ì„±ì: ê¹€ë„ì™„ <dowan.test@gamail.com>
ìƒì„±ì¼: 2025-04-15
ìµœì¢… ìˆ˜ì •ì¼: 2025-04-15
ë²„ì „: 1.0.0

ë³€ê²½ ë‚´ì—­:
- 2025-04-15: Wandb ë¡œê¹… ì¶”ê°€ (ê¹€ë„ì™„)
"""

import torch
from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import DataLoader
from models import Uni_Sign
import utils as utils
from datasets_ours import S2T_Dataset
import os
import time
import argparse, json, datetime
from pathlib import Path
import math
import sys
from timm.optim import create_optimizer
from models import get_requires_grad_dict
from SLRT_metrics import translation_performance, islr_performance, wer_list
from transformers import get_scheduler
from config import *

import wandb

def main(args):
    utils.init_distributed_mode_ds(args)

    print(args)
    utils.set_seed(args.seed)

    # --- 2. Wandb Initialization (Main Process Only) ---
    if utils.is_main_process():
        # í”„ë¡œì íŠ¸ ì´ë¦„, ì‹¤í–‰ ì´ë¦„ ë“±ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        run_name = f"{args.dataset}_{args.task}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"
        wandb.init(
            project="Uni-Sign-Finetuning", # <-- ì›í•˜ëŠ” í”„ë¡œì íŠ¸ ì´ë¦„ìœ¼ë¡œ ë³€ê²½
            name=run_name,
            config=vars(args), # í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ configì— ì €ì¥
            mode="online" if args.wandb_online else "disabled" # wandb í™œì„±í™”/ë¹„í™œì„±í™” ì œì–´
        )
    # ----------------------------------------------------

    print(f"Creating dataset:")
        
    train_data = S2T_Dataset(path=train_label_paths[args.dataset], 
                             args=args, phase='train')
    print(train_data)
    train_sampler = torch.utils.data.distributed.DistributedSampler(train_data,shuffle=True)
    train_dataloader = DataLoader(train_data,
                                 batch_size=args.batch_size, 
                                 num_workers=args.num_workers, 
                                 collate_fn=train_data.collate_fn,
                                 sampler=train_sampler, 
                                 pin_memory=args.pin_mem,
                                 drop_last=True)
    
    dev_data = S2T_Dataset(path=dev_label_paths[args.dataset], 
                           args=args, phase='dev')
    print(dev_data)
    # dev_sampler = torch.utils.data.distributed.DistributedSampler(dev_data,shuffle=False)
    dev_sampler = torch.utils.data.SequentialSampler(dev_data)
    dev_dataloader = DataLoader(dev_data,
                                batch_size=args.batch_size,
                                num_workers=args.num_workers, 
                                collate_fn=dev_data.collate_fn,
                                sampler=dev_sampler, 
                                pin_memory=args.pin_mem)
        
    test_data = S2T_Dataset(path=test_label_paths[args.dataset], 
                            args=args, phase='test')
    print(test_data)
    # test_sampler = torch.utils.data.distributed.DistributedSampler(test_data,shuffle=False)
    test_sampler = torch.utils.data.SequentialSampler(test_data)
    test_dataloader = DataLoader(test_data,
                                 batch_size=args.batch_size,
                                 num_workers=args.num_workers, 
                                 collate_fn=test_data.collate_fn,
                                 sampler=test_sampler, 
                                 pin_memory=args.pin_mem)

    print(f"Creating model:")
    model = Uni_Sign(
                args=args
                )
    model.cuda()
    model.train()
    for name, param in model.named_parameters():
        if param.requires_grad:
            param.data = param.data.to(torch.float32)

    if args.finetune != '':
        print('***********************************')
        print('Load Checkpoint...')
        print('***********************************')
        state_dict = torch.load(args.finetune, map_location='cpu')['model']
    
        # --- ìˆ˜ì •ëœ ë¶€ë¶„ ---
        # í˜„ì¬ ëª¨ë¸ì˜ state_dict ê°€ì ¸ì˜¤ê¸° (í‚¤ ì¡´ì¬ ë° í¬ê¸° ë¹„êµìš©)
        current_model_dict = model.state_dict()
        
        # ì œì™¸í•  í‚¤ ëª©ë¡ (í¬ê¸° ë¶ˆì¼ì¹˜ ë°œìƒ í‚¤)
        keys_to_exclude = []
        # ë¡œë“œí•  state_dictë¥¼ ìˆœíšŒí•˜ë©° í˜„ì¬ ëª¨ë¸ê³¼ í¬ê¸°ê°€ ë‹¤ë¥¸ í‚¤ ì°¾ê¸°
        for k, v in state_dict.items():
            if k in current_model_dict:
                if current_model_dict[k].shape != v.shape:
                    keys_to_exclude.append(k)
                    print(f"Excluding key due to size mismatch: {k}. Checkpoint shape: {v.shape}, Model shape: {current_model_dict[k].shape}")
            # else: # ì²´í¬í¬ì¸íŠ¸ì—ëŠ” ìˆì§€ë§Œ ëª¨ë¸ì—ëŠ” ì—†ëŠ” í‚¤ (unexpected key) - strict=Falseê°€ ì²˜ë¦¬í•´ì¤Œ
    
        # ì›ë³¸ state_dictë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³ , ì œì™¸í•  í‚¤ë¥¼ ëº€ ìƒˆë¡œìš´ dict ìƒì„±
        filtered_state_dict = {k: v for k, v in state_dict.items() if k not in keys_to_exclude}
        
        if keys_to_exclude:
            print(f"Total {len(keys_to_exclude)} keys excluded due to size mismatch.")
    
        # í•„í„°ë§ëœ state_dictë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œë“œ (strict=FalseëŠ” ì—¬ì „íˆ ìœ íš¨)
        ret = model.load_state_dict(filtered_state_dict, strict=False)
        # ---------------

        # print('Missing keys: \n', '\n'.join(ret.missing_keys))
        # print('Unexpected keys: \n', '\n'.join(ret.unexpected_keys))
    
    model_without_ddp = model
    if args.distributed:
        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)
        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu], find_unused_parameters=True)
        model_without_ddp = model.module
    n_parameters = utils.count_parameters_in_MB(model_without_ddp)
    print(f'number of params: {n_parameters}M')

    optimizer = create_optimizer(args, model_without_ddp)
    lr_scheduler = get_scheduler(
                name='cosine',
                optimizer=optimizer,
                num_warmup_steps=int(args.warmup_epochs * len(train_dataloader)/args.gradient_accumulation_steps),
                num_training_steps=int(args.epochs * len(train_dataloader)/args.gradient_accumulation_steps),
            )
    
    model, optimizer, lr_scheduler = utils.init_deepspeed(args, model, optimizer, lr_scheduler)
    model_without_ddp = model.module.module
    # print(model_without_ddp)
    print(optimizer)

    output_dir = Path(args.output_dir)

    start_time = time.time()
    max_accuracy = 0
    if args.task == "CSLR":
        max_accuracy = 1000
    
    if args.eval:
        if utils.is_main_process():
            if args.task != "ISLR":
                print("ğŸ“„ dev result")
                evaluate(args, dev_dataloader, model, model_without_ddp, phase='dev')
                # --- Log evaluation metrics to wandb ---
                if wandb.run is not None:
                    log_dict_dev = {f'eval_dev/{k}': v for k, v in dev_stats.items()}
                    wandb.log(log_dict_dev, step=0) # step 0 ë˜ëŠ” ì ì ˆí•œ ê°’
            print("ğŸ“„ test result")
            evaluate(args, test_dataloader, model, model_without_ddp, phase='test')
            # --- Log evaluation metrics to wandb ---
            if wandb.run is not None:
                log_dict_test = {f'eval_test/{k}': v for k, v in test_stats.items()}
                wandb.log(log_dict_test, step=0)
        # --- 4. Finish Wandb Run ---
        if utils.is_main_process() and wandb.run is not None:
            wandb.finish()
        return 
    print(f"Start training for {args.epochs} epochs")

    for epoch in range(0, args.epochs):
        if args.distributed:
            train_sampler.set_epoch(epoch)
        
        print(f"epoch {epoch}")
        train_stats = train_one_epoch(args, model, train_dataloader, optimizer, epoch)

        # --- 3. Log training metrics to wandb (Main Process Only) ---
        if utils.is_main_process() and wandb.run is not None:
            log_dict_train = {f'train/{k}': v for k, v in train_stats.items()}
            log_dict_train['epoch'] = epoch
            # í˜„ì¬ learning rate ë¡œê¹… (DeepSpeed ì‚¬ìš© ì‹œ optimizer êµ¬ì¡° í™•ì¸ í•„ìš”)
            current_lr = optimizer.param_groups[0]['lr']
            log_dict_train['train/learning_rate'] = current_lr
            wandb.log(log_dict_train) # ê¸°ë³¸ì ìœ¼ë¡œ global step ì‚¬ìš©, epoch ê¸°ì¤€ìœ¼ë¡œ í•˜ë ¤ë©´ commit=False í›„ ë³„ë„ ë¡œê·¸
        # -------------------------------------------------------------
        
        if args.output_dir:
            checkpoint_paths = [output_dir / f'checkpoint_{epoch}.pth']
            for checkpoint_path in checkpoint_paths:
                utils.save_on_master({
                    'model': get_requires_grad_dict(model_without_ddp),
                }, checkpoint_path)
            
            # adapter_save_dir = f"{output_dir}/'checkpoint_apapter_{epoch}'" # ì–´ëŒ‘í„° ì €ì¥ ë””ë ‰í† ë¦¬
            # uni_sign_weights_save_path = f"{output_dir}/'checkpoint_uni_sign_{epoch}.pth'" # Uni-Sign ìì²´ ê°€ì¤‘ì¹˜ íŒŒì¼
        
            # # 1. LoRA ì–´ëŒ‘í„° ì €ì¥
            # model_without_ddp.lora_model.save_pretrained(adapter_save_dir)
            # model_without_ddp.gemma_tokenizer.save_pretrained(adapter_save_dir)
            # print(f"LoRA adapter saved to {adapter_save_dir}")
        
            # # 2. Uni-Sign ìì²´ ê°€ì¤‘ì¹˜ ì €ì¥ (Gemma ë° LoRA ì œì™¸)
            # uni_sign_state_dict = {}
            # # lora_model ë‚´ë¶€ íŒŒë¼ë¯¸í„° ì´ë¦„ ì ‘ë‘ì‚¬ í™•ì¸ (ì˜ˆ: 'lora_model.')
            # lora_prefix = "lora_model."
            # # ë˜ëŠ” Gemma ëª¨ë¸ íŒŒë¼ë¯¸í„° ì´ë¦„ ì ‘ë‘ì‚¬ í™•ì¸ (ì˜ˆ: 'gemma_model.') - Uni_Sign êµ¬ì¡°ì— ë”°ë¼ ë‹¤ë¦„
            # # gemma_prefix = "gemma_model." # í˜¹ì€ lora_model ë‚´ë¶€ì˜ base_model ì ‘ê·¼ ê²½ë¡œ
        
            # for name, param in model_without_ddp.named_parameters():
            #     # LoRA ëª¨ë¸(PeftModel) ë˜ëŠ” ê·¸ ë‚´ë¶€ì˜ ë² ì´ìŠ¤ ëª¨ë¸ íŒŒë¼ë¯¸í„°ê°€ ì•„ë‹ˆë©´ ì €ì¥
            #     if not name.startswith(lora_prefix): # Uni_Sign ë‚´ lora_model ê°ì²´ ì´ë¦„ ê¸°ì¤€
            #        # ë§Œì•½ gemma_modelë„ ë³„ë„ ì†ì„±ìœ¼ë¡œ ìˆë‹¤ë©´ ê·¸ê²ƒë„ ì œì™¸
            #        # if not name.startswith(gemma_prefix): # Uni_Sign ë‚´ gemma_model ê°ì²´ ì´ë¦„ ê¸°ì¤€
            #        uni_sign_state_dict[name] = param.cpu().clone() # CPUë¡œ ë³µì‚¬í•˜ì—¬ ì €ì¥
        
            # if uni_sign_state_dict: # ì €ì¥í•  ê°€ì¤‘ì¹˜ê°€ ìˆë‹¤ë©´
            #     utils.save_on_master({'uni_sign_weights': uni_sign_state_dict}, uni_sign_weights_save_path)
            #     print(f"Uni-Sign specific weights saved to {uni_sign_weights_save_path}")
            # else:
            #     print("No Uni-Sign specific weights found to save (excluding LoRA/Gemma).")

        # single gpu inference
        if utils.is_main_process():
            test_stats = evaluate(args, dev_dataloader, model, model_without_ddp, phase='dev')
            # evaluate(args, test_dataloader, model, model_without_ddp, phase='test')    # í…ŒìŠ¤íŠ¸ì…‹ ê²€ì¦ ì œê±°

            # --- 3. Log evaluation metrics to wandb ---
            if wandb.run is not None:
                log_dict_eval = {}
                for k, v in test_stats.items():
                    log_dict_eval[f'dev/{k}'] = v
                # for k, v in test_stats.items():
                #     log_dict_eval[f'test/{k}'] = v
                # epoch ê¸°ì¤€ìœ¼ë¡œ ë¡œê¹… (wandb stepê³¼ ë³„ê°œë¡œ ê´€ë¦¬ ê°€ëŠ¥)
                log_dict_eval['epoch'] = epoch
                wandb.log(log_dict_eval)
            # ------------------------------------------
            
            if args.task == "SLT":
                if max_accuracy < test_stats["bleu4"]:
                    max_accuracy = test_stats["bleu4"]
                    if args.output_dir and utils.is_main_process():
                        checkpoint_paths = [output_dir / 'best_checkpoint.pth']
                        for checkpoint_path in checkpoint_paths:
                            utils.save_on_master({
                                'model': get_requires_grad_dict(model_without_ddp),
                            }, checkpoint_path)

                print(f"BLEU-4 of the network on the {len(dev_dataloader)} dev videos: {test_stats['bleu4']:.2f}")
                print(f'Max BLEU-4: {max_accuracy:.2f}%')
            
            elif args.task == "ISLR":
                if max_accuracy < test_stats["top1_acc_pi"]:
                    max_accuracy = test_stats["top1_acc_pi"]
                    if args.output_dir and utils.is_main_process():
                        checkpoint_paths = [output_dir / 'best_checkpoint.pth']
                        for checkpoint_path in checkpoint_paths:
                            utils.save_on_master({
                                'model': get_requires_grad_dict(model_without_ddp),
                            }, checkpoint_path)

                print(f"PI accuracy of the network on the {len(dev_dataloader)} dev videos: {test_stats['top1_acc_pi']:.2f}")
                print(f'Max PI accuracy: {max_accuracy:.2f}%')
            
            elif args.task == "CSLR":
                if max_accuracy > test_stats["wer"]:
                    max_accuracy = test_stats["wer"]
                    if args.output_dir and utils.is_main_process():
                        checkpoint_paths = [output_dir / 'best_checkpoint.pth']
                        for checkpoint_path in checkpoint_paths:
                            utils.save_on_master({
                                'model': get_requires_grad_dict(model_without_ddp),
                            }, checkpoint_path)
                            
                print(f"WER of the network on the {len(dev_dataloader)} dev videos: {test_stats['wer']:.2f}")
                print(f'Min WER: {max_accuracy:.2f}%')
        
            log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},
                        **{f'test_{k}': v for k, v in test_stats.items()},
                        'epoch': epoch,
                        'n_parameters': n_parameters}
            
        if args.output_dir and utils.is_main_process():
            with (output_dir / "log.txt").open("a") as f:
                f.write(json.dumps(log_stats) + "\n")
        
    total_time = time.time() - start_time
    total_time_str = str(datetime.timedelta(seconds=int(total_time)))
    print('Training time {}'.format(total_time_str))

    # --- 4. Final Evaluation on Test Set (after loop) ---
    if utils.is_main_process():
        print("\n--- Training Finished ---")
        print("Loading best model checkpoint for final test evaluation...")
        best_checkpoint_path = output_dir / 'best_checkpoint.pth'

        if best_checkpoint_path.exists():
            checkpoint = torch.load(best_checkpoint_path, map_location='cpu')

            # state_dict ì¶”ì¶œ (ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡°ì— ë”°ë¼ í‚¤ í™•ì¸)
            if 'model' in checkpoint:
                best_state_dict = checkpoint['model']
            else:
                best_state_dict = checkpoint # íŒŒì¼ ìì²´ê°€ state_dict ì¼ ê²½ìš°

            # Load best weights into the model
            # get_requires_grad_dict ë¡œ ì €ì¥í–ˆìœ¼ë¯€ë¡œ strict=False ì‚¬ìš© ê¶Œì¥
            load_result = model_without_ddp.load_state_dict(best_state_dict, strict=False)
            print(f"Loaded best checkpoint from {best_checkpoint_path}")
            # ë¡œë“œ ê²°ê³¼ ìƒì„¸ ì¶œë ¥ (ì„ íƒ ì‚¬í•­)
            # print(f"  Missing keys count: {len(load_result.missing_keys)}")
            # print(f"  Unexpected keys count: {len(load_result.unexpected_keys)}")

            print("\n--- Evaluating on Test Set with Best Model ---")
            # evaluate í•¨ìˆ˜ í˜¸ì¶œ
            final_test_stats = evaluate(args, test_dataloader, model, model_without_ddp, phase='test')

            print("\n--- Final Test Set Performance (Best Model based on Dev Set) ---")
            # ê²°ê³¼ ì¶œë ¥
            for key, value in final_test_stats.items():
                 # ì†Œìˆ˜ì  ì•„ë˜ 4ìë¦¬ê¹Œì§€ í¬ë§·íŒ…í•˜ì—¬ ì¶œë ¥
                 print(f"  {key}: {value:.4f}")

            # Log final test stats to wandb
            if wandb.run is not None:
                final_log_dict = {f'final_test/{k}': v for k, v in final_test_stats.items()}
                wandb.log(final_log_dict)
                # wandb ìš”ì•½(Summary) ì—…ë°ì´íŠ¸ -> ëŒ€ì‹œë³´ë“œì—ì„œ ìµœì¢… ê°’ ë³´ê¸° í¸í•¨
                wandb.summary.update(final_log_dict)
                wandb.summary.update({'best_dev_metric': max_accuracy, 'best_epoch': epoch}) # ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ best ëª¨ë¸ì´ ë‚˜ì™”ëŠ”ì§€ ê¸°ë¡

            # Log final test stats to a file
            if args.output_dir:
                with (output_dir / "final_results.txt").open("w") as f:
                    f.write("Final Test Set Performance (Best Model based on Dev Set):\n")
                    f.write(json.dumps(final_test_stats, indent=4) + "\n") # ë³´ê¸° ì¢‹ê²Œ indent ì¶”ê°€
                    f.write(f"\nBest model loaded from: {best_checkpoint_path}\n")
                    # ì–´ë–¤ dev metric ê¸°ì¤€ìœ¼ë¡œ best ì¸ì§€ ëª…ì‹œ
                    metric_name = "metric"
                    if args.task == "SLT": metric_name = "BLEU4"
                    elif args.task == "ISLR": metric_name = "PI Acc"
                    elif args.task == "CSLR": metric_name = "WER"
                    f.write(f"Achieved best Dev {metric_name}: {max_accuracy:.4f}\n")

        else:
            print(f"Warning: Best checkpoint not found at {best_checkpoint_path}. Skipping final test evaluation.")
    # ----------------------------------------------------

    # --- Finish Wandb Run ---
    # ìµœì¢… í‰ê°€ ê²°ê³¼ê¹Œì§€ ë¡œê¹… í›„ ì¢…ë£Œ
    if utils.is_main_process() and wandb.run is not None:
        wandb.finish()
    # ---------------------------

def train_one_epoch(args, model, data_loader, optimizer, epoch):
    model.train()
    
    metric_logger = utils.MetricLogger(delimiter="  ")
    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))
    header = 'Epoch: [{}/{}]'.format(epoch, args.epochs)
    print_freq = 10
    optimizer.zero_grad()

    target_dtype = None
    if model.bfloat16_enabled():
        target_dtype = torch.bfloat16

    for step, (src_input, tgt_input) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):
        if target_dtype != None:
            for key in src_input.keys():
                if isinstance(src_input[key], torch.Tensor):
                    src_input[key] = src_input[key].to(target_dtype).cuda()

        if args.task == "CSLR":
            tgt_input['gt_sentence'] = tgt_input['gt_gloss']
        stack_out = model(src_input, tgt_input)
        total_loss = stack_out['loss']
        model.backward(total_loss)
        model.step()

        loss_value = total_loss.item()
        if not math.isfinite(loss_value):
            print("Loss is {}, stopping training".format(loss_value))
            sys.exit(1)
            
        metric_logger.update(loss=loss_value)
        metric_logger.update(lr=optimizer.param_groups[0]["lr"])

        # if step==30:
        #     break
        
    # gather the stats from all processes
    metric_logger.synchronize_between_processes()
    print("Averaged stats:", metric_logger)

    return  {k: meter.global_avg for k, meter in metric_logger.meters.items()}

def evaluate(args, data_loader, model, model_without_ddp, phase):
    model.eval()

    metric_logger = utils.MetricLogger(delimiter="  ")
    header = 'Test:'

    target_dtype = None
    if model.bfloat16_enabled():
        target_dtype = torch.bfloat16
        
    with torch.no_grad():
        tgt_pres = []
        tgt_refs = []
 
        for step, (src_input, tgt_input) in enumerate(metric_logger.log_every(data_loader, 10, header)):
            if target_dtype != None:
                for key in src_input.keys():
                    if isinstance(src_input[key], torch.Tensor):
                        src_input[key] = src_input[key].to(target_dtype).cuda()
            
            if args.task == "CSLR":
                tgt_input['gt_sentence'] = tgt_input['gt_gloss']
            stack_out = model(src_input, tgt_input)
            
            total_loss = stack_out['loss']
            metric_logger.update(loss=total_loss.item())
        
            output = model_without_ddp.generate(src_input, 
                                                max_new_tokens=100, 
                                                num_beams = 4,
                        )

            for i in range(len(output)):
                tgt_pres.append(output[i])
                tgt_refs.append(tgt_input['gt_sentence'][i])
                ## ----------Debugìš© ì¶œë ¥ê°’ í™•ì¸
                # tgt_pre = model_without_ddp.gemma_tokenizer.decode(output[i], skip_special_tokens=True)
                # tgt_ref = tgt_input['gt_sentence'][i]
                # print(f"Pred: '{tgt_pre}', Ref: '{tgt_ref}', Match: {tgt_pre == tgt_ref}")

    tokenizer = model_without_ddp.gemma_tokenizer
    # ê°’ì´ eos_token_idë¡œ ì„¤ì • ë˜ì–´ìˆìŒ
    padding_value = tokenizer.eos_token_id
    
    pad_tensor = torch.ones(150-len(tgt_pres[0])).cuda() * padding_value
    tgt_pres[0] = torch.cat((tgt_pres[0],pad_tensor.long()),dim = 0)

    tgt_pres = pad_sequence(tgt_pres,batch_first=True,padding_value=padding_value)
    tgt_pres = tokenizer.batch_decode(tgt_pres, skip_special_tokens=True)

    # fix mt5 tokenizer bug
    if args.dataset == 'CSL_Daily' and args.task == "SLT":
        tgt_pres = [' '.join(list(r.replace(" ",'').replace("\n",''))) for r in tgt_pres]
        tgt_refs = [' '.join(list(r.replace("ï¼Œ", ',').replace("ï¼Ÿ","?").replace(" ",''))) for r in tgt_refs]

    if args.task == "SLT":
        bleu_dict, rouge_score = translation_performance(tgt_refs, tgt_pres)
        for k,v in bleu_dict.items():
            metric_logger.meters[k].update(v)
        metric_logger.meters['rouge'].update(rouge_score)
    
    elif args.task == "ISLR":
        top1_acc_pi, top1_acc_pc = islr_performance(tgt_refs, tgt_pres)
        metric_logger.meters['top1_acc_pi'].update(top1_acc_pi)
        metric_logger.meters['top1_acc_pc'].update(top1_acc_pc)
        
    elif args.task == "CSLR":
        wer_results = wer_list(hypotheses=tgt_pres, references=tgt_refs)
        print(wer_results)
        for k,v in wer_results.items():
            metric_logger.meters[k].update(v)

    # # gather the stats from all processes
    # metric_logger.synchronize_between_processes()
    
    if utils.is_main_process() and utils.get_world_size() == 1 and args.eval:
        with open(args.output_dir+f'/{phase}_tmp_pres.txt','w') as f:
            for i in range(len(tgt_pres)):
                f.write(tgt_pres[i]+'\n')
        with open(args.output_dir+f'/{phase}_tmp_refs.txt','w') as f:
            for i in range(len(tgt_refs)):
                f.write(tgt_refs[i]+'\n')
        
    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}

if __name__ == '__main__':
    os.environ["TOKENIZERS_PARALLELISM"] = "false"

    parser = argparse.ArgumentParser('Uni-Sign scripts', parents=[utils.get_args_parser()])
    args = parser.parse_args()

    if args.output_dir:
        Path(args.output_dir).mkdir(parents=True, exist_ok=True)
    main(args)